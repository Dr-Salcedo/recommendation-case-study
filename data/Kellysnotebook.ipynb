{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = pyspark.SparkConf().set('spark.driver.host','127.0.0.1')\n",
    "sc = pyspark.SparkContext('local[*]', conf=conf)\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder \n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kellysnotebook.ipynb movies.txt           requests.json\r\n",
      "LICENSE              \u001b[31mmovies_metadata.csv\u001b[m\u001b[m  user_ratings.csv\r\n",
      "README               pablo_notebook.ipynb users.csv\r\n",
      "movies.csv           ratings.json         users.dat\r\n",
      "movies.dat           ratings_df.csv       users.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ratings = []\n",
    "for line in open('ratings.json', 'r'):\n",
    "    ratings.append(json.loads(line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dict={}\n",
    "ratings_dict['user_id'] = [i['user_id'] for i in ratings]\n",
    "ratings_dict['movie_id'] = [i['movie_id'] for i in ratings]\n",
    "ratings_dict['rating'] = [i['rating'] for i in ratings]\n",
    "ratings_dict['timestamp'] = [i['timestamp'] for i in ratings]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings_df.csv')\n",
    "ratings = ratings.iloc[:,1:]\n",
    "ratings_df['timestamp'] = ratings_df['timestamp'].astype(int)\n",
    "ratings_df.to_csv('ratings_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users.csv')\n",
    "users = users.iloc[:, 1:]\n",
    "users['Zip-code']=users[\"Zip-code\"].apply(lambda x: x[:5])\n",
    "users[\"Zip-code\"]=users[\"Zip-code\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = ratings.merge(users, left_on='user_id', right_on='UserID', how='left')\n",
    "user_ratings =pd.get_dummies(user_ratings, columns=['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings.to_csv('user_ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv('movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "movies['genres'] = movies['genres'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['id'] = movies['id'].str.extract('(\\d+)')\n",
    "movies['id'] = movies['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df = user_ratings.merge(movies, left_on='movie_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df = genres_df.set_index('movie_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_list(row):\n",
    "    genres = []\n",
    "    for i in row:\n",
    "        genres.append(i['name'])\n",
    "    if len(genres) < 3:\n",
    "        return genres\n",
    "    else:\n",
    "        return genres[:3]\n",
    "\n",
    "genres_df['genres'] = genres_df['genres'].apply(genre_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df = pd.get_dummies(genres_df['genres'].apply(pd.Series).stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genres_df.columns\n",
    "genres_df = genres_df.drop(['Aniplex','Foreign', 'TV Movie',\n",
    "       'BROSTA TV', 'Carousel Productions','GoHands', \n",
    "        'Music', 'Odyssey Media', 'Pulser Productions', 'Rogue State', \n",
    "        'Telescene Film Group Productions', 'Vision View Entertainment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df.to_csv('genres.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_ratings.merge(genres_df, on='movie_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('user_ratings_genres.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"rating\"], axis=1)\n",
    "y = df[\"rating\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=142, stratify = y)\n",
    "\n",
    "forest_amount = RandomForestClassifier(n_estimators=30, max_depth= 9)\n",
    "forest_amount.fit(X_train, y_train)\n",
    "forest_amount.score(X_train, y_train) # Accuracy of training data\n",
    "forest_amount.score(X_test, y_test) # Accuracy of test data\n",
    "\n",
    "# plot_feature_importances(forest_amount) # plot using function above\n",
    "def plot_feature_importances(model):\n",
    "   '''plots the importance of each feature.  Useful for something like KNN so you can tell which features are useful '''\n",
    "   n_features = X_train.shape[1]\n",
    "   plt.figure(figsize=(8,8))\n",
    "   plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "   plt.yticks(np.arange(n_features), X_train.columns.values)\n",
    "   plt.xlabel(\"Feature importance\")\n",
    "   plt.ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    AtomicType,\n",
    "    BinaryType,\n",
    "    BooleanType,\n",
    "    ByteType,\n",
    "    CloudPickleSerializer,\n",
    "    DataType,\n",
    "    DataTypeSingleton,\n",
    "    DateConverter,\n",
    "    DateType,\n",
    "    DatetimeConverter,\n",
    "    DecimalType,\n",
    "    DoubleType,\n",
    "    FloatType,\n",
    "    FractionalType,\n",
    "    IntegerType,\n",
    "    IntegralType,\n",
    "    JavaClass,\n",
    "    LongType,\n",
    "    MapType,\n",
    "    NullType,\n",
    "    NumericType,\n",
    "    Row,\n",
    "    ShortType,\n",
    "    SparkContext,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    TimestampType,\n",
    "    UserDefinedType,\n",
    ")\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('index', IntegerType()),\n",
    "        StructField('userId', IntegerType()),\n",
    "        StructField('movieId', IntegerType()),\n",
    "        StructField('rating', FloatType()),\n",
    "        StructField('timestamp', LongType()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "movie_ratings = spark.read.csv('ratings_df.csv',\n",
    "                               inferSchema=False,\n",
    "                               schema=schema,\n",
    "                               header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = movie_ratings.drop(movie_ratings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = movie_ratings.drop(movie_ratings.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6040</td>\n",
       "      <td>858</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6040</td>\n",
       "      <td>2384</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6040</td>\n",
       "      <td>593</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6040</td>\n",
       "      <td>1961</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6040</td>\n",
       "      <td>1419</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0    6040      858     4.0\n",
       "1    6040     2384     4.0\n",
       "2    6040      593     5.0\n",
       "3    6040     1961     4.0\n",
       "4    6040     1419     3.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 503424\n",
      "Test Dataset Count: 216525\n"
     ]
    }
   ],
   "source": [
    "(trainingdata, testdata) = movie_ratings.randomSplit([0.7,0.3], seed = 10)\n",
    "print(\"Training Dataset Count: \" + str(trainingdata.count()))\n",
    "print(\"Test Dataset Count: \" + str(testdata.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=10,\n",
    "    userCol='userId',\n",
    "    itemCol='movieId',\n",
    "    ratingCol='rating',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model = als.fit(trainingdata)\n",
    "predictions = als_model.transform(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8779395229385331"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol='rating')\n",
    "evaluator.evaluate(predictions.na.drop(), {evaluator.metricName: \"rmse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
